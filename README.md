# ELT de Dados do SteamDB Sales com BigQuery e Google Sheets

Este projeto realiza um processo de **ELT (Extract, Load, Transform)** dos dados de promoÃ§Ãµes de jogos disponÃ­veis no site [SteamDB Sales](https://steamdb.info/sales/). 

O fluxo automatiza a extraÃ§Ã£o de dados com **Playwright**, realiza a carga no **Google BigQuery**, e finalmente disponibiliza os dados em uma **[planilha do Google Sheets](https://docs.google.com/spreadsheets/d/1V8AsvW6Z6zQCE5Gedhbn-yQFxjeYRe3ynlyXXpZ3XPw/edit?usp=sharing)** para consulta e visualizaÃ§Ã£o.

---

## ğŸ“‹ **Fluxo do Processo**

### 1. **ExtraÃ§Ã£o dos Dados**
- **Tecnologia Utilizada**: [Playwright](https://playwright.dev/).
- Os dados da pÃ¡gina de promoÃ§Ãµes do SteamDB foram extraÃ­dos automaticamente.
- ApÃ³s a extraÃ§Ã£o, os dados foram salvos localmente em arquivos no formato CSV.

### 2. **Carga no BigQuery**
- Os arquivos CSV foram carregados em um dataset no **Google BigQuery**.
- Foi configurada a criaÃ§Ã£o automÃ¡tica de tabelas com base no schema detectado nos arquivos CSV.
- O BigQuery agora contÃ©m os dados centralizados e prontos para consultas SQL.

### 3. **TransformaÃ§Ã£o e DisponibilizaÃ§Ã£o no Google Sheets**
- Os dados do BigQuery foram lidos e carregados em uma **planilha do Google Sheets**.
- Caso a planilha ou aba nÃ£o existissem, elas foram criadas dinamicamente pelo script.

---

## ğŸ“¦ **Estrutura do Projeto**

```plaintext
project/
|
â”œâ”€â”€ beanalytics_venv        # DiretÃ³rio onde o ambiente virtual Ã© criado (diretÃ³rio nÃ£o versionado no Git)
â”‚
â”œâ”€â”€ configs/                # Arquivos de credenciais (nÃ£o versionados no Git)
â”‚   â””â”€â”€ credentials.json    # Arquivo com as credenciais de acesso ao BigQuery
â”‚
â”œâ”€â”€ jobs/                    # DiretÃ³rio onde os Jupyter Notebooks estÃ£o salvos
â”‚   â”œâ”€â”€ extract.ipynb       # ExtraÃ§Ã£o de dados usando Playwright
â”‚   â”œâ”€â”€ load.ipynb          # Carga dos dados no Google BigQuery
â”‚   â””â”€â”€ transform.ipynb     # ExportaÃ§Ã£o para o Google Sheets
â”‚
â”œâ”€â”€ raw/                    # DiretÃ³rio onde os arquivos CSV sÃ£o salvos (nÃ£o versionados no Git)
â”‚   â”œâ”€â”€ steam_sales_1.csv
â”‚   â”œâ”€â”€ steam_sales_2.csv
â”‚   â””â”€â”€ ...
â”‚
â”œâ”€â”€ .gitignore              # Lista de arquivos ignorados pelo Git
â”œâ”€â”€ 00_install_requirements # Script bash para instalaÃ§Ã£o do pip e venv
â”œâ”€â”€ 01_create_venv          # Script bash para criaÃ§Ã£o do ambiente virtual e instalaÃ§Ã£o do pacotes necessÃ¡rios
â”œâ”€â”€ README.md               # DocumentaÃ§Ã£o do projeto
â””â”€â”€ requirements.txt       # DependÃªncias do projeto
```

## ğŸš€ PrÃ©-requisitos

### 1. Sistema Linux

### 2. Python 3.8+
Certifique-se de ter o Python instalado. VocÃª pode verificar a versÃ£o executando:
```bash
python3 --version
```

### 3. ExecuÃ§Ã£o dos scripts Bash
```bash
./00_install_requirements
```
```bash
./01_create_venv
```
### 4. Configurar as credenciais:

* Criar uma conta de serviÃ§o no Google Cloud com acesso ao BigQuery e ao Google Sheets.
* Baixar o arquivo `credentials.json` e armazenÃ¡-lo no diretÃ³rio `credentials/`.

## âš™ï¸ Como Executar

**Selecionar o Kernel do Ambiente Virtual:**

* No Jupyter, clique em **Kernel > Change Kernel**.
* Selecione Python (.venv).

## ğŸ› ï¸ Tecnologias Utilizadas

* [Playwright](https://playwright.dev/): AutomaÃ§Ã£o do navegador para extraÃ§Ã£o de dados.
* [Beautiful Soup](https://www.crummy.com/software/BeautifulSoup/bs4/doc/): Parsing de HTML para extraÃ§Ã£o de dados estruturados.
* [Google BigQuery](https://cloud.google.com/bigquery?hl=pt_br): Data warehouse para armazenamento e consulta de dados.
* [Google Sheets API](https://developers.google.com/sheets/api/quickstart/python?hl=pt-br): IntegraÃ§Ã£o para disponibilizar os dados em planilhas.
* Python Bibliotecas:
    * `playwright`
    * `bs4`
    * `google-cloud-bigquery`
    * `google-api-python-client`
    * `pandas`

## ğŸ“ˆ Objetivo
Este projeto demonstra como construir um pipeline de **ELT**:

* **ExtraÃ§Ã£o** de dados nÃ£o estruturados da web.
* **Carga** de dados para um banco de dados escalÃ¡vel (BigQuery).
* **TransformaÃ§Ã£o** e disponibilizaÃ§Ã£o dos dados para usuÃ¡rios finais em uma planilha.

## ğŸ“ Notas
* **Credenciais**: As credenciais da conta de serviÃ§o nÃ£o estÃ£o versionadas no repositÃ³rio. Certifique-se de configurÃ¡-las corretamente antes de executar os scripts.
* **AutomaÃ§Ã£o**: Este pipeline pode ser agendado usando ferramentas como **Apache Airflow** ou **Cron** para atualizaÃ§Ãµes periÃ³dicas dos dados.

## ğŸ¤ ContribuiÃ§Ãµes
ContribuiÃ§Ãµes sÃ£o bem-vindas! Sinta-se Ã  vontade para enviar sugestÃµes ou melhorias. ğŸš€